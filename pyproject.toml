[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "nanollama"
version = "0.0.0"
description = "Experiments regarding LLM memory offloading"
readme = "README.md"
requires-python = ">=3.9"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
dependencies = [
  "fire",           # argument parsing
  "jinja2",         # template rendering
  "numpy",
  "pyaml",          # configuration
  "torch",
]

[project.optional-dependencies]
dev = [
  "pytest",             # testing
  "ruff",               # formatting
  "torch_tb_profiler",  # visualizing profiling trace with tensorboard
  "viztracer",          # visualizing profiling trace with perfetto
  "wandb",              # logging
]

llm = [
  "sentencepiece",  # tokenizer
  "tiktoken",       # tokenizer
  "blobfile",       # tiktoken dependency
]

visu = [
  "ipykernel",    # jupyter notebooks
  "ipywidgets",   # jupyter widgets
  "matplotlib",   # plots 
  "nbformat",     # jupyter format
  "pandas",       # dataframes
  "plotly",       # interactive plots
]

ssm = [
  "accelerated_scan",
  "causal_conv1d",
  "mamba_ssm",
]

database = [
  psycopg2
]

[tool.setuptools.packages.find]
where = ["src"]
exclude = ["src.apps"]

[tool.ruff]
line-length = 120

[tool.ruff.lint]
select = [
  "E", "F", "W",  # Default rules
  "ANN001",       # Function arguments should annotate types
  "ANN201",       # Public function should annotate return type
  "B",            # Common bugs
  "DTZ",          # Timezone issues
  "I",            # Sort inputs
  "PLE",          # Common errors
  "RUF100",       # Remove unused noqa
  "UP",           # Modern syntax
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]