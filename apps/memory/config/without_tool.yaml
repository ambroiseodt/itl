launcher:
  name: mem_tool
  overwrite: true
  log_dir: $HOME/memory_tool

  script: apps.memory.train

  slurm:
    # partition: scavenge
    mem: 16G
    nodes: 1
    nb_gpus: 1        # use torchrun, or slurm, for multi-gpu runs
    time: 10          # job time in minutes
    signal_time: 60   # alert time in seconds

run_config:
  cluster:
    compile_model: true

  data:
    key: qa
    n_data: 100
    batch_size: 128
    seq_len: 256
    padding: true
    tokenizer:
      name: byte
      special_tokens:
        <|user|>: 0
        <|assistant|>: 1
        <|database|>: 2
        <|eod|>: 3

  model:
    implementation: transformer
    vocab_size: 300
    emb_dim: 64
    nb_layers: 2
    block:
      nb_heads: 2
      hidden_dim: 256

  optim:
    steps: 1000
    lr: 1e-3
    weight_decay: 0.1
    fused: true
    warmup: 50
    lr_min_ratio: 0

  orchestration:
    utils:
      seed: 100

    checkpoint:
      nb_kept: 3

    logging:
      period: 1
    wandb:
      active: false

    profiler:
      active: true
      heavy: false
      wait: 1
      steps: 20

  evaluation:
    period: 200
    asynchronous: true

    db_path: data/memory/people.db
    data:
      asynchronous: false

    checkpoint:
      path: $HOME/tmp_eval.jsonl
